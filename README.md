# ML Email Classifier ğŸš€

[![Made with â¤ï¸ by mths0](https://img.shields.io/badge/Made%20By-mths0-blue)](https://github.com/mths0)
[![Made with â¤ï¸ by Saudll](https://img.shields.io/badge/Made%20By-Saudll-blue)](https://github.com/Saudll)



This project is a **Machine Learning-based Email Classifier** that detects whether an email is **Spam** or **Ham (Not Spam)** using a **Multinomial NaÃ¯ve Bayes** model trained on a text dataset.

It is structured based on a simplified **Cookiecutter Data Science** format and ready for deployment.

---

## ğŸ§  Project Goal

The main goal is to **build an accurate spam detection system** using:
- Data balancing techniques
- TF-IDF feature extraction
- Hyperparameter tuning (`alpha`, n-grams)
- Model evaluation using Precision, Recall, F1-Score
- A final trained model ready for deployment

---

## ğŸ“‚ Project Structure

<pre>
â”œâ”€â”€ LICENSE                
â”œâ”€â”€ README.md              
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ raw                
â”‚   â””â”€â”€ external           
â”‚
â”œâ”€â”€ models                 <- Saved trained models
â”‚
â”œâ”€â”€ notebooks              
â”‚
â”œâ”€â”€ references             
â”‚
â”œâ”€â”€ reports
â”‚   â””â”€â”€ figures            
â”‚
â”œâ”€â”€ requirements.txt       <- List of Python libraries used
â”‚
â””â”€â”€ src                    
    â”œâ”€â”€ spam_email_classifier.py
    â”œâ”€â”€ data_analys.ipynb          
    â”œâ”€â”€ GUI.py
    â”‚   
    â”‚   
    â”‚   
    â””â”€â”€ services
        
</pre>

---

ğŸ“ˆ Main Features
Preprocessing: Tokenization, stopword removal, stemming

Balancing Data: Upsampling spam samples for better learning

Feature Extraction: TF-IDF with n-grams (1,2)

Model: Multinomial NaÃ¯ve Bayes with tuned alpha

Evaluation: Accuracy, Precision, Recall, F1-Score, Confusion Matrix

Live Testing: Enter email text and get instant prediction (spam or ham)

## ğŸ“Š Results

During the development, different versions of the model were trained and evaluated to improve performance.
Hereâ€™s a summary of the experiments:

| Model Version                    | Accuracy | Ham Precision | Ham Recall | Spam Precision | Spam Recall | Notes |
|-----------------------------------|----------|---------------|------------|----------------|-------------|-------|
| **Default** (No tuning)           | 96%      | 0.95          | 1.00       | 1.00           | 0.66        | Model biased towards ham |
| **TF-IDF tuned** (ngram 1â€“2,
|            min_df=5, max_df=0.9)  | 97%      | 0.96          | 0.98       | 0.98           | 0.96        | Bigram features helped |
| **NaÃ¯ve Bayes (Î± = 0.5)**         | 98%      | 0.97          | 0.98       | 0.98           | 0.97        | Smoother model |
| **NaÃ¯ve Bayes (Î± = 0.3)**         | 99%      | 0.99          | 0.99       | 1.00           | 0.99        | Best balance achieved |
| **NaÃ¯ve Bayes (Î± = 0.1)**         | 99%      | 0.99          | 0.99       | 0.99           | 0.99        | Sharpest decision boundary |

âœ… **Final Best Model**:  
- **Vectorizer Settings**: `TfidfVectorizer(max_df=0.9, min_df=5, ngram_range=(1,2))`
- **Classifier**: `MultinomialNB(alpha=0.3)`
- **Test Accuracy**: **99%**
- **Spam Recall**: **99%**  
- **Spam Precision**: **100%**


---

### ğŸ“‹ Key Observations:

- Without balancing the dataset, the model missed a lot of spam (low recall 66%).
- Adding n-grams helped the model detect spam **phrases** (like "click here" or "free money").
- Fine-tuning the `alpha` parameter increased confidence without overfitting.
- The final model detects **both spam and ham** emails almost perfectly.

---

## ğŸ† Conclusion

After balancing the data, engineering better features (bigrams), and tuning NaÃ¯ve Bayes hyperparameters (`alpha`), the classifier was able to achieve:

> **99% Accuracy**  
> **99% Spam Recall**  
> **99% Spam Precision**

---

âš¡ Tech Stack
Python 3.10+

scikit-learn

NLTK

pandas

matplotlib

seaborn



ğŸ™Œ Credits
Created with â¤ï¸ by mohannad and Saud






